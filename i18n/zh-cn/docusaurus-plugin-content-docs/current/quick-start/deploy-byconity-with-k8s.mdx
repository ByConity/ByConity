---
title: 在 Kubernetes 上部署 ByConity
tags:
  - Docs
---

# 在 Kubernetes 上部署 ByConity

本文演示了如何在 Kubernetes 集群中部署 ByConity 集群。

## 本地部署一个 demo

### Prerequisites

- 在本地环境中安装和设置 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)
- 在本地环境中安装 [helm](https://helm.sh/)
- 安装[kind](https://kind.sigs.k8s.io/)和[Docker](https://www.docker.com/)
- 签出 conity-deploy 代码查看

```bash
git clone git@github.com:ByConity/byconity-deploy.git
cd byconity-deploy
```

### 使用 Kind 配置本地 Kubernetes 集群

> 警告：Kind 不是为生产用途而设计的。
> macOS 用户请注意：您可能需要增加容器的[可用内存](https://docs.docker.com/desktop/get-started/#resources)（建议 6 GB）。

这将创建一个 1-control-plane、3-worker 的 Kubernetes 集群。

```bash
kind create cluster --config examples/kind/kind-byconity.yaml
```

测试以确保本地 kind 集群已准备就绪： 

```bash
kubectl cluster-info
```

### 初始化 Byconity 演示集群

```bash
# Install with fdb CRD first
helm upgrade --install --create-namespace --namespace byconity -f ./examples/kind/values-kind.yaml byconity ./chart/byconity --set fdb.enabled=false

# Install with fdb cluster
helm upgrade --install --create-namespace --namespace byconity -f ./examples/kind/values-kind.yaml byconity ./chart/byconity
```

等到所有 Pod 准备就绪。

```bash
kubectl -n byconity get po
```

让我们试试吧！

```
$ kubectl -n byconity exec -it sts/byconity-server -- bash
root@byconity-server-0:/# clickhouse client

172.16.1.1 :)
```

### 从 Kubernetes 集群中删除或停止 ByConity

```bash
helm uninstall --namespace byconity byconity
```

如果您想暂时停止它，请在您的机器上停止它

```bash
docker stop byconity-cluster-control-plane byconity-cluster-worker byconity-cluster-worker2 byconity-cluster-worker3
```

## 部署在您自建的 Kubernetes 中



### 如何部署或购买 Kubernetes 集群？

您可以在这里获取信息：[生产环境](https://kubernetes.io/docs/setup/production-environment/)

### 先决条件

- 在本地环境中安装和设置 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) 
- 在本地环境中安装 [helm](https://helm.sh/) 

### 准备您的存储

为了获得最佳的 [TCO](https://en.wikipedia.org/wiki/Total_cost_of_ownership) 和性能，本地磁盘最好与 ByConity server 和 worker 一起使用。 

> ByConity server 和 worker 的存储仅用于磁盘缓存，您可以随时删除它们。

您可以使用 [OpenEBS local PV](https://openebs.io/docs/concepts/localpv) 等存储.

### 准备你自己的 helm 值文件

您可以从 ./chart/byconity/values.yaml 复制并修改一些字段，例如：

- 存储类名
- 时区
- 服务器/工人的副本
- hdfs存储请求

  如果您想使用自己现有的HDFS集群，请将hdfs.enabled设置为true。您可以在values.yaml中覆盖HDFS的配置
```dash
byconity:
  hdfs_address: hdfs://your own hdfs:port
hdfs:
  enabled: false
```
- fdb configuration

  如果您想使用自己的FDB，请将fdb.enabled和fdb-operator.enabled都设置为false。您可以参考values_use_existing_fdb.yaml进行配置
```dash
byconity:
  hdfs_address: hdfs://byconity-hdfs-namenodes:8020 # can using your own hdfs
  use_existing_fdb: true
  fdb_cluster_file: your fdb-cluster-file content. #byconity_fdb:Is0hBgl6iICdHuspBmhAODmD5WISXKzI@192.168.224.150:4501,192.168.226.83:4501,192.168.228.152:4501
fdb:
  enabled: false
fdb-operator:
  enabled: false
```


### 初始化 Byconity 集群

```bash
# Install with fdb CRD first
helm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity --set fdb.enabled=false

# Install with fdb cluster
helm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity
```

等到所有 Pod 准备就绪。

```bash
kubectl -n byconity get po
```

让我们试试吧！

```
$ kubectl -n byconity exec -it sts/byconity-server -- bash
root@byconity-server-0:/# clickhouse client

172.16.1.1 :)
```

## 测试

### 运行一些 SQL 来测试

```sql
CREATE DATABASE IF NOT EXISTS test;
USE test;
DROP TABLE IF EXISTS test.lc;
CREATE TABLE test.lc (b LowCardinality(String)) engine=CnchMergeTree ORDER BY b;
INSERT INTO test.lc SELECT '0123456789' FROM numbers(100000000);
SELECT count(), b FROM test.lc group by b;
DROP TABLE IF EXISTS test.lc;
DROP DATABASE test;
```

## 更新您的 Byconity 集群

### 添加新的虚拟数据仓库 

假设您要为您的用户添加 2 个虚拟数据仓库，5 个副本用于my-new-vw-default读取，2 个副本用于my-new-vw-write写入。

修改你的 values.yaml


```yaml
byconity:
  virtualWarehouses:
    ...

    - <<: *defaultWorker
      name: my-new-vw-default
      replicas: 5
    - <<: *defaultWorker
      name: my-new-vw-write
      replicas: 2
```

使用新值应用 helm 版本

```bash
helm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity
```
运行`CREATE WAREHOUSE` 数据定义语言 在Byconity创建逻辑虚拟仓库

```sql
CREATE WAREHOUSE IF NOT EXISTS `my-new-vw-default` SETTINGS num_workers = 0, type = 'Read';
CREATE WAREHOUSE IF NOT EXISTS `my-new-vw-write` SETTINGS num_workers = 0, type = 'Write';
```

完毕。现在让我们创建一个表并使用您的新虚拟数据仓库！

```sql
-- Create a table with SETTINGS cnch_vw_default = 'my-new-vw-default', cnch_vw_write = 'my-new-vw-write'
CREATE DATABASE IF NOT EXISTS test;
CREATE TABLE test.lc2 (b LowCardinality(String)) engine=CnchMergeTree
ORDER BY b
SETTINGS cnch_vw_default = 'my-new-vw-default', cnch_vw_write = 'my-new-vw-write';

-- Check if the table has the new settings
SHOW CREATE TABLE test.lc2;
```

### 在原有的VirtualWareHouse扩缩容 

假设您有一个my-new-vw-default，希望扩容增加2个worker，可以直接更新Kubernetes的资源对象statefulset：

首先使用如下命令，获取当前 Kubernetes 集群中所有 StatefulSet 资源的名称
```bash
kubectl get statefulset
```

然后，找到并打开该配置，做如下修改

```bash
kubectl edit statefulset.apps/my-new-vw-default
```

把配置"replicas: 1" 变更为 "replicas: 2"

```yaml
spec:
  podManagementPolicy: OrderedReady
  replicas: 2   #由1变更为2 
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: byconity
      app.kubernetes.io/name: byconity
      byconity-role: worker
      byconity-vw: vw_default
  serviceName: my-new-vw-default
```

更新完后使用kubectl可以查看VirtualWarehouse已经扩容包含2个woker

## 配置 Byconity 高可用集群（可选）
高可用的ByConity集群功能开启需要打开所有组件的zookeeper配置，参考[server.yaml](https://github.com/ByConity/byconity-deploy/blob/master/chart/byconity/files/server.yaml#L96)

打开zookeeper配置：

```yaml
  partition_by: event_date
  flush_interval_milliseconds: 15000
  mark_cache_size: 5368709120
  zookeeper: {} # enable zookeeper
  cnch_config: /etc/byconity/cnch-config.yaml
```

官方提供了高可用的helm配置yaml文件[value_HA_example.yaml](https://github.com/ByConity/byconity-deploy/blob/master/examples/k8s/value_HA_example.yaml)供参考。

使用helm更新集群：
```bash
helm upgrade --install --create-namespace --namespace byconity -f ./your/custom/values.yaml byconity ./chart/byconity
```


