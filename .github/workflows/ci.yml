name: CI
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  scm_build:
    name: Build binary and run stateless tests
    container: byconity/byconity-ci:latest
    runs-on: self-hosted
    steps:
      - name: Check out repository code
        uses: actions/checkout@v3
      - name: Build binary with build_bin.sh
        env:
          CUSTOM_CMAKE_BUILD_TYPE: "Release"
        run: |
          git config --global --add safe.directory /__w/ByConity/ByConity
          git -C "$GITHUB_WORKSPACE" submodule sync
          git -C "$GITHUB_WORKSPACE" submodule update --init --recursive --force
          ./build_bin.sh
      - name: run unit tests
        run: |
          bash $GITHUB_WORKSPACE/unittest.sh
          echo "COMPOSE_PROJECT_NAME=byconity-$(cat /etc/hostname)" >> $GITHUB_ENV
      - name: Set environment variables
        run: |
          echo "BINARY_VOL=${COMPOSE_PROJECT_NAME}_bin_volume" >> $GITHUB_ENV
          echo "HDFS_VOL=${COMPOSE_PROJECT_NAME}_hdfs_volume" >> $GITHUB_ENV
          echo "CONFIG_VOL=${COMPOSE_PROJECT_NAME}_config_volume" >> $GITHUB_ENV
          echo "SCRIPTS_VOL=${COMPOSE_PROJECT_NAME}_scripts_volume" >> $GITHUB_ENV
          echo "CLICKHOUSE_PORT_TCP=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "CLICKHOUSE_PORT_HTTP=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "CLICKHOUSE_PORT_HDFS=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "FS_PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "HIVE_SERVER_PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "HMS_PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
          echo "HIVE_NAMENODE_PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')" >> $GITHUB_ENV
      - name: Create ByConity Cluster
        run: |
          mkdir /CI/
          cd /CI/
          cp -r $GITHUB_WORKSPACE/docker/ci-deploy/* ./          
          cp $GITHUB_WORKSPACE/docker/ci-deploy/.env ./
          mkdir bin
          cp -r $GITHUB_WORKSPACE/build/programs/* ./bin
          sed -i "s|COMPOSE\_PROJECT\_NAME|${COMPOSE_PROJECT_NAME}|g" conf/core-site.xml
          sed -i "s|COMPOSE\_PROJECT\_NAME|${COMPOSE_PROJECT_NAME}|g" config/fdb.cluster
          sed -i "s|COMPOSE\_PROJECT\_NAME|${COMPOSE_PROJECT_NAME}|g" config/cnch-config.yml
          sed -i "s|COMPOSE\_PROJECT\_NAME|${COMPOSE_PROJECT_NAME}|g" config/daemon-manager.yml
          echo "Create volumes for ByConity Cluster"
          /bin/bash create_docker_volume_ci.sh
          echo "Bring up ByConity Cluster"
          docker-compose up -d
          sleep 10
          conf/create_users.sh
          echo "CLICKHOUSE_HOST=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.Gateway}}{{end}}' ${COMPOSE_PROJECT_NAME}_server-0)" >> $GITHUB_ENV
          export CLICKHOUSE_HOST=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.Gateway}}{{end}}' ${COMPOSE_PROJECT_NAME}_server-0)
          echo "Check connection to ByConity Server"
          curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 $CLICKHOUSE_HOST:$CLICKHOUSE_PORT_HTTP
          echo "Check status of cluster"
          docker ps --filter name=$COMPOSE_PROJECT_NAME
      - name: Run ByConity FuntionalStateless (w.o optimizer)
        continue-on-error: true
        run: |
          cd /CI/
          export EXTRA_OPTIONS='enable_optimizer_fallback=0'
          cp -r $GITHUB_WORKSPACE/docker/test/stateless/process_functional_tests_result.py ./
          cp -r $GITHUB_WORKSPACE/tests/clickhouse-test ./
          mkdir queries
          cp -r $GITHUB_WORKSPACE/tests/queries/4_cnch_stateless queries/
          cp -r $GITHUB_WORKSPACE/tests/queries/shell_config.sh queries/
          mkdir -p /test_output
          ./clickhouse-test -b $GITHUB_WORKSPACE/build/programs/clickhouse --stop --hung-check --jobs 4 --order asc --print-time --client-option ${EXTRA_OPTIONS} 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a /test_output/test_result.txt
          ./process_functional_tests_result.py || echo -e "failure\tCannot parse results" > /test_output/check_status.tsv
      - name: Run ByConity FuntionalStateless (w optimizer)
        continue-on-error: true
        run: |
          mkdir -p ci_stateless_with_optimizer
          cd ci_stateless_with_optimizer
          cp -r $GITHUB_WORKSPACE/docker/test/stateless/process_functional_tests_result.py ./
          cp -r $GITHUB_WORKSPACE/tests/clickhouse-test ./
          mkdir queries
          cp -r $GITHUB_WORKSPACE/tests/queries/4_cnch_stateless queries/
          cp -r $GITHUB_WORKSPACE/tests/queries/shell_config.sh queries/
          mkdir -p test_output
          export EXTRA_OPTIONS='enable_optimizer_fallback=0 enable_optimizer=1'
          ./clickhouse-test -b $GITHUB_WORKSPACE/build/programs/clickhouse --stop --hung-check --jobs 4 --order asc --print-time --client-option ${EXTRA_OPTIONS} 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
          ./process_functional_tests_result.py --in-results-dir ./test_output/ --out-results-file /test_output/stateless_with_optimizer_test_results.txt --out-status-file /test_output/check_status.tsv || echo -e "failure\tCannot parse results" > /test_output/check_status.tsv
          cd ..
          rm -rf ci_stateless_with_optimizer
      - name: Run ByConity ClickhouseSQL FuntionalStateless (w.o optimizer)
        continue-on-error: true
        run: |
          mkdir -p ci_clickhouse_sql
          cd ci_clickhouse_sql
          export EXTRA_OPTIONS='enable_optimizer_fallback=0'
          cp -r $GITHUB_WORKSPACE/docker/test/stateless/process_functional_tests_result.py ./
          cp -r $GITHUB_WORKSPACE/tests/clickhouse-test ./
          mkdir queries
          cp -r $GITHUB_WORKSPACE/tests/queries/7_clickhouse_sql queries/
          cp -r $GITHUB_WORKSPACE/tests/queries/shell_config.sh queries/
          echo "Running test without optimizer"
          mkdir -p test_output
          ./clickhouse-test -b $GITHUB_WORKSPACE/build/programs/clickhouse --stop --hung-check --jobs 1 --order asc --print-time --client-option ${EXTRA_OPTIONS} 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
          ./process_functional_tests_result.py --in-results-dir ./test_output/ --out-results-file /test_output/clickhouse_sql_test_results.txt --out-status-file /test_output/check_status.tsv || echo -e "failure\tCannot parse results" > /test_output/check_status.tsv
          cd ..
          rm -rf ci_clickhouse_sql
#          not run test with optimizer enable at the moment
#          echo "Running test with optimizer"
#          ./clickhouse-test --stop --hung-check --jobs 1 --order asc --print-time --client-option 'enable_optimizer=1' 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
      - name: After test
        if: always()
        continue-on-error: true
        run: |
          bash $GITHUB_WORKSPACE/.codebase/ci_scripts/common_component/copy_core_to_shared.sh || true # copy core to artifact folder
          bash $GITHUB_WORKSPACE/.codebase/ci_scripts/common_component/copy_case_stdout_to_shared.sh || true # copy stdout to artifact folder
          docker ps -a --format "{{.ID}} {{.Names}} {{.Image}}" --filter name=$COMPOSE_PROJECT_NAME | grep "byconity/debian:buster-runit-fdb7.1.27" | awk {'print $1"\t"$2'} | xargs -n 2 sh -c 'mkdir -p /test_output/$2; docker cp -q $1:/var/byconity/out.log /test_output/$2/out.log' sh || true
          docker ps -a --format "{{.ID}} {{.Names}} {{.Image}}" --filter name=$COMPOSE_PROJECT_NAME | grep "byconity/debian:buster-runit-fdb7.1.27" | awk {'print $1"\t"$2'} | xargs -n 2 sh -c 'mkdir -p /test_output/$2; docker cp -q $1:/var/byconity/err.log /test_output/$2/err.log' sh || true
          mv /test_output /Artifacts  && tar --warning=no-file-changed -zcf  /Artifacts.tar.gz /Artifacts/*  || true
          bash .codebase/ci_scripts/common_component/block_ci.sh || true # check block_ci_flag
      - name: Upload Artifact
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@v2
        with:
          name: Artifacts
          path: /Artifacts.tar.gz
      - name: Analyse Result
        run:
          /bin/bash $GITHUB_WORKSPACE/docker/test/result.sh
      - name: Cleanup
        if: always()
        run: |
          cd /CI/
          docker-compose down --volumes
