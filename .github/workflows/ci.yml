name: CI
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]

jobs:
  scm_build:
    name: Build binary and run stateless tests
    container: byconity/byconity-ci:latest
    runs-on: self-hosted
    steps:
      - name: Check out repository code
        uses: actions/checkout@v3
      - name: Build binary with build_bin.sh
        env:
          CUSTOM_CMAKE_BUILD_TYPE: "Release"
        run: |
          git config --global --add safe.directory /__w/ByConity/ByConity
          git -C "$GITHUB_WORKSPACE" submodule sync
          git -C "$GITHUB_WORKSPACE" submodule update --init --recursive
          ./build_bin.sh
      - name: run unit tests
        run: |
          bash $GITHUB_WORKSPACE/unittest.sh
      - name: Create ByConity Cluster
        run: |
          mkdir /CI/
          cd /CI/
          cp -r $GITHUB_WORKSPACE/docker/local-deploy/* ./          
          cp $GITHUB_WORKSPACE/docker/local-deploy/.env ./
          cp $GITHUB_WORKSPACE/ci_scripts/create_docker_volume_ci.sh ./
          mkdir bin
          cp -r $GITHUB_WORKSPACE/build/programs/* ./bin
          docker container rm 37b654514308 442895bb9103 58baa5210504 3f55a56fd684 771bfb1723ca c8fc37f7b44c 4fd9251cb961 013348c42641 714b11c6df46 87cc4e718724
          docker container ls -a
          export COMPOSE_PROJECT_NAME=byconity_$(cat /etc/hostname)
          export BINARY_VOL=${COMPOSE_PROJECT_NAME}_bin_volume
          export HDFS_VOL=${COMPOSE_PROJECT_NAME}_hdfs_volume
          export CONFIG_VOL=${COMPOSE_PROJECT_NAME}_config_volume
          /bin/bash create_docker_volume_ci.sh
          docker-compose -f docker-compose.yml.multiworkers up -d --remove-orphans
          sleep 10
          hdfs/create_users.sh
          export CLICKHOUSE_HOST=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.Gateway}}{{end}}' server-0)
          curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 $CLICKHOUSE_HOST:8124
      - name: Run ByConity FuntionalStateless
        continue-on-error: true
        run: |
          cd /CI/
          cp -r $GITHUB_WORKSPACE/docker/test/stateless/process_functional_tests_result.py ./
          cp -r $GITHUB_WORKSPACE/tests/clickhouse-test ./
          mkdir queries
          cp -r $GITHUB_WORKSPACE/tests/queries/4_cnch_stateless queries/
          cp -r $GITHUB_WORKSPACE/tests/queries/shell_config.sh queries/
          mkdir -p /test_output
          export CLICKHOUSE_PORT_TCP=9000
          export CLICKHOUSE_PORT_HTTP=8124
          export CLICKHOUSE_HOST=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.Gateway}}{{end}}' server-0)
          ./clickhouse-test -b $GITHUB_WORKSPACE/build/programs/clickhouse --stop --hung-check --jobs 4 --order asc --print-time 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a /test_output/test_result.txt
          ./process_functional_tests_result.py || echo -e "failure\tCannot parse results" > /test_output/check_status.tsv
      - name: Run ByConity ClickhouseSQL FuntionalStateless (w.o optimizer)
        continue-on-error: true
        run: |
          mkdir -p ci_clickhouse_sql
          cd ci_clickhouse_sql
          cp -r $GITHUB_WORKSPACE/docker/test/stateless/process_functional_tests_result.py ./
          cp -r $GITHUB_WORKSPACE/tests/clickhouse-test ./
          mkdir queries
          cp -r $GITHUB_WORKSPACE/tests/queries/7_clickhouse_sql queries/
          cp -r $GITHUB_WORKSPACE/tests/queries/shell_config.sh queries/
          export CLICKHOUSE_PORT_TCP=9000
          export CLICKHOUSE_PORT_HTTP=8124
          export CLICKHOUSE_HOST=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.Gateway}}{{end}}' server-0)
          echo "Running test without optimizer"
          mkdir -p test_output
          ./clickhouse-test -b $GITHUB_WORKSPACE/build/programs/clickhouse --stop --hung-check --jobs 1 --order asc --print-time 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
          ./process_functional_tests_result.py --in-results-dir ./test_output/ --out-results-file /test_output/clickhouse_sql_test_results.txt --out-status-file /test_output/check_status.tsv || echo -e "failure\tCannot parse results" > /test_output/check_status.tsv
          cd ..
          rm -rf ci_clickhouse_sql
#          not run test with optimizer enable at the moment.
#          echo "Running test with optimizer".
#          ./clickhouse-test --stop --hung-check --jobs 1 --order asc --print-time --client-option 'enable_optimizer=1' 2>&1 | ts '%Y-%m-%d %H:%M:%S' | tee -a test_output/test_result.txt
      - name: After test
        continue-on-error: true
        run: |
          bash $GITHUB_WORKSPACE/.codebase/ci_scripts/common_component/copy_core_to_shared.sh || true # copy core to artifact folder
          bash $GITHUB_WORKSPACE/.codebase/ci_scripts/common_component/copy_case_stdout_to_shared.sh || true # copy stdout to artifact folder
          mv /test_output /Artifacts  && tar --warning=no-file-changed -zcf  /Artifacts.tar.gz /Artifacts/*  || true
          bash .codebase/ci_scripts/common_component/block_ci.sh || true # check block_ci_flag
      - name: Upload Artifact
        uses: actions/upload-artifact@v2
        with:
          name: Artifacts
          path: /Artifacts.tar.gz
      - name: Analyse Result
        run:
          /bin/bash $GITHUB_WORKSPACE/docker/test/result.sh
      - name: Cleanup
        if: always()
        run: |
          cd /CI/
          export COMPOSE_PROJECT_NAME=byconity_$(cat /etc/hostname)
          export BINARY_VOL=${COMPOSE_PROJECT_NAME}_bin_volume
          export HDFS_VOL=${COMPOSE_PROJECT_NAME}_hdfs_volume
          export CONFIG_VOL=${COMPOSE_PROJECT_NAME}_config_volume
          docker-compose -f docker-compose.yml.multiworkers down --volumes
