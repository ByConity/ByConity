version: "3"
services:
# hdfs / remote fs
  hdfs:
    image: gchq/hdfs:3.3
    command: namenode
    container_name: "${COMPOSE_PROJECT_NAME}-hdfs-namenode"
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop/conf
    ports:
      - "${CLICKHOUSE_PORT_HDFS}:9870"
    volumes:
      - hdfs_volume:/etc/hadoop/conf
      - /var/log/hadoop
      - /data1
      - /data2

  hdfs-datanode:
    depends_on:
      - hdfs
    image: gchq/hdfs:3.3
    command: datanode
    container_name: "${COMPOSE_PROJECT_NAME}-hdfs-datanode"
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop/conf
    volumes:
      - hdfs_volume:/etc/hadoop/conf
      - /var/log/hadoop
      - /data1
      - /data2

# foundation db / catalog
  fdb:
    image: foundationdb/foundationdb:7.1.24
    environment:
      FDB_NETWORKING_MODE: container
      FDB_COORDINATOR_PORT: 4550
      FDB_PORT: 4550
    container_name: "${COMPOSE_PROJECT_NAME}_fdb-0"

# byconity:
  tso:
    image: byconity/debian:buster-runit-fdb7.1.27
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/; fdbcli -C /config/fdb.cluster --exec \"configure new single ssd\"; tso-server --config-file /config/tso.yml"
    depends_on:
      - fdb
      - hdfs
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    # evironment:
    container_name: "${COMPOSE_PROJECT_NAME}_tso-0"
    cap_add:
      - SYS_PTRACE

  resource-manager:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_tso-0:18845 && resource-manager --config-file /config/resource-manager.yml"
    depends_on:
      - tso
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    container_name: "${COMPOSE_PROJECT_NAME}_resource-manager-0"
    cap_add:
      - SYS_PTRACE

  server:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_tso-0:18845 && clickhouse-server --config-file /config/server.yml"
    depends_on:
      - tso
      - hdfs
    ports:
      - "${CLICKHOUSE_PORT_TCP}:52145"
      - "${CLICKHOUSE_PORT_HTTP}:21557"
    container_name: "${COMPOSE_PROJECT_NAME}_server-0"
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    cap_add:
      - SYS_PTRACE

  worker-write:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_server-0:21557 && VIRTUAL_WAREHOUSE_ID=vw_write WORKER_GROUP_ID=wg_write WORKER_ID=w0 clickhouse-server --config-file /config/worker.yml"
    depends_on:
      - server
    container_name: "${COMPOSE_PROJECT_NAME}_worker-write-0"
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    cap_add:
      - SYS_PTRACE

  worker-default-0:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_server-0:21557  && VIRTUAL_WAREHOUSE_ID=vw_default WORKER_GROUP_ID=wg_default WORKER_ID=r0 clickhouse-server --config-file /config/worker.yml"
    depends_on:
      - server
    container_name: "${COMPOSE_PROJECT_NAME}_worker-default-0"
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    cap_add:
      - SYS_PTRACE

  worker-default-1:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_server-0:21557  && VIRTUAL_WAREHOUSE_ID=vw_default WORKER_GROUP_ID=wg_default WORKER_ID=r1 clickhouse-server --config-file /config/worker.yml"
    depends_on:
      - server
    container_name: "${COMPOSE_PROJECT_NAME}_worker-default-1"
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    cap_add:
      - SYS_PTRACE

  daemon-manager:
    image: byconity/debian:buster-runit-fdb7.1.27
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command: bash -c "export PATH=$PATH:/opt/byconity/bin/ && curl --retry 10 --retry-delay 5 --retry-connrefused --retry-max-time 120 --max-time 120 ${COMPOSE_PROJECT_NAME}_server-0:21557  && daemon-manager --config-file ./config/daemon-manager.yml"
    depends_on:
      - server
    container_name: "${COMPOSE_PROJECT_NAME}_daemon-manager-0"
    volumes:
      - binary_volume:/opt/byconity/bin/
      - config_volume:/config/
    cap_add:
      - SYS_PTRACE

  # HIVE docker-compose
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    env_file:
      - ./.env
    container_name: ${COMPOSE_PROJECT_NAME}_namenode
    ports:
      - "${FS_PORT}:8120"
      - "${HIVE_NAMENODE_PORT}:50070"

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    environment:
      COMPOSE_PROJECT_NAME: ${COMPOSE_PROJECT_NAME}
      SERVICE_PRECONDITION: "${COMPOSE_PROJECT_NAME}_namenode:50070"
    env_file:
      - ./.env
    container_name: ${COMPOSE_PROJECT_NAME}_datanode


  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    environment:
      COMPOSE_PROJECT_NAME: ${COMPOSE_PROJECT_NAME}
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://${COMPOSE_PROJECT_NAME}_hive-metastore-postgresql:5432/metastore"
      SERVICE_PRECONDITION: "${COMPOSE_PROJECT_NAME}_hive-metastore:9083"
    env_file:
      - ./.env
    container_name: ${COMPOSE_PROJECT_NAME}_hive-server
    volumes:
      - scripts:/mnt/scripts
    ports:
      - "${HIVE_SERVER_PORT}:10000"
    depends_on:
      - datanode
      - namenode

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    command: /bin/bash /mnt/scripts/hive-metastore.sh
    environment:
      COMPOSE_PROJECT_NAME: ${COMPOSE_PROJECT_NAME}
      SERVICE_PRECONDITION: "${COMPOSE_PROJECT_NAME}_namenode:50070 ${COMPOSE_PROJECT_NAME}_datanode:50075 ${COMPOSE_PROJECT_NAME}_hive-metastore-postgresql:5432"
    env_file:
      - ./.env
    container_name: ${COMPOSE_PROJECT_NAME}_hive-metastore
    volumes:
      - scripts:/mnt/scripts
    ports:
      - "${HMS_PORT}:9083"
    depends_on:
      - hive-metastore-postgresql
      - datanode
      - namenode

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: ${COMPOSE_PROJECT_NAME}_hive-metastore-postgresql
    environment:
      COMPOSE_PROJECT_NAME: ${COMPOSE_PROJECT_NAME}

volumes:
    config_volume:
      name: "${CONFIG_VOL}"
    hdfs_volume:
      name: "${HDFS_VOL}"
    binary_volume:
      name: "${BINARY_VOL}"
    namenode:
      name: "${COMPOSE_PROJECT_NAME}_namenode_volume"
    datanode:
      name: "${COMPOSE_PROJECT_NAME}_datanode_volume"
    scripts:
      name: "${SCRIPTS_VOL}"
